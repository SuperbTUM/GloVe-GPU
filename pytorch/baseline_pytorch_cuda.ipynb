{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "baseline_pytorch_cuda.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1MuodhOVaMEt",
    "outputId": "db2d56dc-7254-45eb-99ca-b3e5dbde2b8e"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive/\")\n",
    "import sys\n",
    "import os\n",
    "path = \"/content/drive/My Drive\"\n",
    "sys.path.append(path)\n",
    "os.chdir(path)\n",
    "%cd CUDA_OpenCL/"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive/\n",
      "/content/drive/My Drive/CUDA_OpenCL\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mbwVuTd1m73c"
   },
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3F7FAlFFaeJb"
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from prefetch_generator import BackgroundGenerator"
   ],
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wm6fLLQznCcg",
    "outputId": "1e724222-1f76-475b-af66-c4ea63dd7ca2"
   },
   "source": [
    "!nvidia-smi"
   ],
   "execution_count": 53,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mon Oct 25 22:39:59 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 470.74       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   37C    P0    33W / 250W |   1043MiB / 16280MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ezeX0lsum4vY"
   },
   "source": [
    "## Design the network"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WaQST2HeaRdv"
   },
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, vocab_size=251, context_len=4, embedding_dim=16, hidden_dim=128):\n",
    "        super(Model, self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.context_len = context_len\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
    "                                      embedding_dim=embedding_dim)\n",
    "        self.hidden = nn.Linear(embedding_dim * context_len, hidden_dim, bias=True)\n",
    "        self.hidden_activated = nn.Sigmoid()\n",
    "        self.output = nn.Linear(hidden_dim, vocab_size * context_len, bias=True)\n",
    "        self.output_activated = nn.Softmax(dim=-1)  # (B, NV)\n",
    "\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight.data, std=0.01)\n",
    "                nn.init.constant_(m.bias.data, 0.0)\n",
    "            elif isinstance(m, nn.Embedding):\n",
    "                nn.init.normal_(m.weight.data, std=0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = torch.zeros((x.shape[0], self.embedding_dim * self.context_len), device=torch.device('cuda:0'))\n",
    "        for i in range(self.context_len):\n",
    "            emb[:, self.embedding_dim * i: (i+1) * self.embedding_dim] = self.embedding(x)[:, i, :]\n",
    "        hid = self.hidden(emb)\n",
    "        hid_ac = self.hidden_activated(hid)\n",
    "        out = self.output(hid_ac)\n",
    "        max_along_dim = out.max(dim=1).values.view(-1, 1)\n",
    "        out -= max_along_dim\n",
    "        shape_out = out.shape\n",
    "        out = out.view(shape_out[0], shape_out[1] // self.vocab_size, self.vocab_size)\n",
    "        out_ac = self.output_activated(out)\n",
    "        return out_ac.reshape(shape_out)\n",
    "\n",
    "\n",
    "class GloVeDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        super(GloVeDataset, self).__init__()\n",
    "        self.train_inputs = data[\"train_inputs\"]\n",
    "\n",
    "    def __len__(self):\n",
    "        if isinstance(self.train_inputs, np.ndarray):\n",
    "            return self.train_inputs.shape[0]\n",
    "        else:\n",
    "            return len(self.train_inputs)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        context = self.train_inputs[item]\n",
    "        return context\n",
    "\n",
    "\n",
    "def sample_input_mask(batch_size, context_length):\n",
    "    \"\"\"Samples a binary mask for the inputs of size batch_size x context_len\n",
    "    For each row, at most one element will be 1.\n",
    "    \"\"\"\n",
    "    mask_idx = torch.randint(context_length, size=(batch_size,))\n",
    "    mask = torch.zeros((batch_size, context_length),\n",
    "                       dtype=torch.int32)  # Convert to one hot B x N, B batch size, N context len\n",
    "    mask[torch.arange(batch_size), mask_idx] = 1\n",
    "    return mask\n",
    "\n",
    "\n",
    "def indicator_matrix(input_masked, mask_zero=True):\n",
    "    batch_size, context_length = input_masked.shape\n",
    "    target_batch = torch.zeros((batch_size, context_length * vocab_size))\n",
    "    targets_offset = (torch.arange(context_length) * vocab_size).unsqueeze(0).repeat_interleave(batch_size, dim=0)\n",
    "    input_masked += targets_offset\n",
    "    input_masked = input_masked.numpy()\n",
    "    target_batch = target_batch.numpy()\n",
    "    targets_offset = targets_offset.numpy()\n",
    "    for c in range(context_length):\n",
    "        target_batch[np.arange(batch_size), input_masked[:, c]] = 1.\n",
    "        if mask_zero:\n",
    "            target_batch[np.arange(batch_size), targets_offset[:, c]] = 0.\n",
    "    return torch.Tensor(target_batch)\n",
    "\n",
    "\n",
    "class DataLoaderX(DataLoader):\n",
    "    def __iter__(self):\n",
    "        return BackgroundGenerator(super().__iter__())\n",
    "      \n",
    "class CELoss(nn.Module):\n",
    "    def __init__(self, reduction=\"sum\"):\n",
    "        super().__init__()\n",
    "        self.reduction = reduction\n",
    "    \n",
    "    def forward(self, target_batch, output_activated):\n",
    "        if self.reduction == \"sum\":\n",
    "            return -(target_batch * torch.log(output_activated + 1e-6)).sum()\n",
    "        elif self.reduction == \"mean\":\n",
    "            return -(target_batch * torch.log(output_activated + 1e-6)).sum() / target_batch.shape[0]"
   ],
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3oTyJmIOkQVw"
   },
   "source": [
    "## Check the network parameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B0HjgW-0iljW",
    "outputId": "22138e41-4279-4fd7-c5d1-0b84d886224e"
   },
   "source": [
    "model = Model().cuda()\n",
    "for name, parameters in model.named_parameters():\n",
    "    print(name,':',parameters.size())"
   ],
   "execution_count": 45,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "embedding.weight : torch.Size([251, 16])\n",
      "hidden.weight : torch.Size([128, 64])\n",
      "hidden.bias : torch.Size([128])\n",
      "output.weight : torch.Size([1004, 128])\n",
      "output.bias : torch.Size([1004])\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXdZutiQkVM5"
   },
   "source": [
    "## train the network"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5GSswe3ajG-",
    "outputId": "26fd515c-0d86-4229-9190-4b961e46bcce"
   },
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    start = time.time()\n",
    "    epochs = 10\n",
    "    batch_size = 100\n",
    "    data = pickle.load(open(\"data.pk\", \"rb\"))\n",
    "    vocab_size = len(data[\"vocab\"])\n",
    "    data_inputs = data[\"train_inputs\"]\n",
    "    context_length = data[\"train_inputs\"].shape[1]\n",
    "    mask = sample_input_mask(batch_size, context_length)\n",
    "    model = Model(vocab_size)\n",
    "    model = model.cuda()\n",
    "    model.train()\n",
    "    optimizer = torch.optim.SGD(model.parameters(), lr=.1, momentum=.9)\n",
    "    lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=.5)\n",
    "    losses = []\n",
    "    for epoch in range(epochs):\n",
    "        loss_avg = 0.\n",
    "        dataloader = DataLoaderX(GloVeDataset(data), batch_size=batch_size, shuffle=True,\n",
    "                                num_workers=4, pin_memory=True)\n",
    "        for sample in tqdm(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "            input_masked = sample * (1 - mask)\n",
    "            input_masked = input_masked.cuda()\n",
    "            target_masked = sample * mask\n",
    "            input_masked_expand = indicator_matrix(target_masked)\n",
    "            input_masked_expand = input_masked_expand.cuda()\n",
    "            \n",
    "            output = model(input_masked)\n",
    "            loss = CELoss(reduction=\"mean\")(input_masked_expand, output)\n",
    "            loss.backward()\n",
    "            loss_avg += loss.cpu().detach().numpy()\n",
    "            nn.utils.clip_grad_norm_(model.parameters(), 10.0)\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "        losses.append(loss_avg / (data_inputs.shape[0] // batch_size))\n",
    "    end = time.time()\n",
    "    print(\"PyTorch GPU implementation time is {:.3f} seconds.\".format(end-start))"
   ],
   "execution_count": 52,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 3725/3725 [00:16<00:00, 229.90it/s]\n",
      "100%|██████████| 3725/3725 [00:15<00:00, 233.49it/s]\n",
      "100%|██████████| 3725/3725 [00:15<00:00, 233.86it/s]\n",
      "100%|██████████| 3725/3725 [00:15<00:00, 233.50it/s]\n",
      "100%|██████████| 3725/3725 [00:15<00:00, 234.37it/s]\n",
      "100%|██████████| 3725/3725 [00:15<00:00, 232.95it/s]\n",
      "100%|██████████| 3725/3725 [00:15<00:00, 234.75it/s]\n",
      "100%|██████████| 3725/3725 [00:16<00:00, 232.74it/s]\n",
      "100%|██████████| 3725/3725 [00:16<00:00, 232.36it/s]\n",
      "100%|██████████| 3725/3725 [00:16<00:00, 232.46it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "PyTorch GPU implementation time is 159.941 seconds.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ]
  }
 ]
}